{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類のビルトインアルゴリズムを使って猫の写真を分類する\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# はじめに\n",
    "***\n",
    "\n",
    "このノートブックは、Amazon SageMaker Ground Truth でラベリングした結果を使って画像分類モデルを作成するためのノートブックです。このノートブックを使用する前に、Amazon SageMaker Ground Truth を使って画像のラベリングが完了している必要があります。\n",
    "\n",
    "Amazon SageMaker Ground Truth を使った画像のラベリング方法については [こちらの記事](https://aws.amazon.com/jp/builders-flash/202003/sagemaker-groundtruth-cat/) をご参照ください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期設定\n",
    "***\n",
    "\n",
    "## 環境設定\n",
    "\n",
    "まずはじめに、**みなさまの環境に合わせて以下の変数の値を変更します。**各変数に設定すべき値は以下の手順で確認可能です。\n",
    "\n",
    "1. **labeling_job_name**<br>\n",
    "Amazon SageMaker コンソールの左側のメニューの [ラベリングジョブ] をクリックし、ラベリングジョブ一覧を表示させます。ここの [名前] 欄にあるのがラベリングジョブ名です。該当のラベリングジョブ名をコピーしてこちらに設定します。\n",
    "1. **your_augmented_manifest_file**<br>\n",
    "上記手順で表示したラベリングジョブ一覧の中から使用したいラベリングジョブをクリックします。[ラベリングジョブの概要] 部分に [出力データセットの場所] というリンクがあるのでそちらをクリックします。そこから manifests -> output とフォルダをたどると output.manifest があります。そちらをクリックし、[コピーパス] というボタンをクリックすると、output.manifest ファイルの S3 パスがコピーされるので、それをペーストします。\n",
    "1. **object_categories**<br>\n",
    "上記手順で　[出力データセットの場所] というリンクをクリック後、annotation-tool フォルダをクリックすると、data.json というファイルがあります。こちらをクリックし [ダウンロード] ボタンをクリックしてダウンロードします。テキストエディタなどでこのファイルを開くと、ラベリング時に使用したラベル名と順番がわかりますので、こちらを参考に設定します。順番さえ同じであれば、アルファベットのラベル名をカタカナなどにしてこちらに設定しても問題ありません。\n",
    "1. **width, height**<br>\n",
    "上記手順1 で表示したラベリングジョブ一覧の中から使用したいラベリングジョブをクリックします。[ラベル付きデータセットオブジェクト] 部分に画像が表示されるので、そちらをクリックするとその画像が保存されている S3 パスがわかります。こちらから画像をダウンロードして、画像のサイズを確認できます。\n",
    "\n",
    "変数の設定が完了したら、セルを選択した状態で Shift + Enter を実行するか、上にある Run ボタンをクリックするとセルが実行されます。セルというのは、ソースコードが書かれたテキスト領域のことです。セルを実行すると、セルの左側にある In [ ]: のカッコの中に数字が表示されます。セルの処理が実行中の場合は数字ではなく * が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon SageMaker Ground Truth のラベリングジョブ名\n",
    "labeling_job_name = 'yujimurata-car-image-labeling'\n",
    "\n",
    "# Amazon SageMaker Ground Truth のラベリング結果の output.manifest の S3パス\n",
    "your_augmented_manifest_file = 's3://yujimurata-car-image-dataset/labeled_data/yujimurata-car-image-labeling/manifests/output/output.manifest'\n",
    "\n",
    "# Amazon SageMaker Ground Truth で使用したラベルの名前。ラベリング時と順番を揃える必要があります。\n",
    "object_categories = ['Crossover', 'Truck', 'SUV', 'Car', 'Others']\n",
    "\n",
    "\n",
    "# 学習に使用する画像（Amazon SageMaker Ground Truth でラベリングした画像）のサイズ\n",
    "width = 800\n",
    "height = 600\n",
    "channel = 3 # 基本的にここは変更する必要はありません。カラー画像であればたいてい RGB の 3チャネルです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker を使うための設定\n",
    "\n",
    "ここでは、AWS のサービスを使う上で必要な設定を行います。こちらは変更の必要はありません。どんどんセルを実行していきましょう。\n",
    "\n",
    "* このノートブックインスタンスで使用しているロールの情報の取得\n",
    "* デフォルト S3 バケット名の取得。こちらに学習したモデルなどを保存します\n",
    "* The Amazon SageMaker の画像分類アルゴリズムの docker イメージパスの取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::430477916104:role/service-role/AmazonSageMaker-ExecutionRole-20211013T152104\n",
      "CPU times: user 286 ms, sys: 5.8 ms, total: 292 ms\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'ic-transfer-learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "Defaulting to the only supported framework/algorithm version: 1. Ignoring framework/algorithm version: latest.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501404015308.dkr.ecr.ap-northeast-1.amazonaws.com/image-classification:1\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習データの準備\n",
    "***\n",
    "\n",
    "ここでは、Amazon SageMaker Ground Truth でラベリングした結果を、学習用と検証用に分けて S3 にアップロードします。こちらは変更の必要はありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://yujimurata-car-image-dataset/labeled_data/yujimurata-car-image-labeling/manifests/output/output.manifest to ../../../tmp/output.manifest\r\n"
     ]
    }
   ],
   "source": [
    "# S3 から output.manifest をダウンロード\n",
    "tmp_manifest = '/tmp/output.manifest'\n",
    "! aws s3 cp {your_augmented_manifest_file} {tmp_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.manifest を学習用と検証用に分割\n",
    "\n",
    "import random\n",
    "\n",
    "with open(tmp_manifest) as f:\n",
    "    data = [l.rstrip() for l in f.readlines()]\n",
    "    \n",
    "line_count = len(data)\n",
    "num_training_samples = int(line_count * 0.7)\n",
    "\n",
    "index = list(range(0, line_count))\n",
    "random.shuffle(index)\n",
    "\n",
    "train_data  = data[:num_training_samples]\n",
    "valid_data = data[num_training_samples:]\n",
    "\n",
    "train_manifest = '/tmp/train.manifest'\n",
    "valid_manifest = '/tmp/valid.manifest'\n",
    "with open(train_manifest, 'w') as f:\n",
    "    for d in train_data:\n",
    "        f.write(\"%s\\n\" % d)\n",
    "with open(valid_manifest, 'w') as f:\n",
    "    for d in valid_data:\n",
    "        f.write(\"%s\\n\" % d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../../tmp/train.manifest to s3://yujimurata-car-image-dataset/labeled_data/yujimurata-car-image-labeling/manifests/output/train.manifest\n",
      "upload: ../../../tmp/valid.manifest to s3://yujimurata-car-image-dataset/labeled_data/yujimurata-car-image-labeling/manifests/output/valid.manifest\n"
     ]
    }
   ],
   "source": [
    "# 学習用と検証用の manifest ファイルを S3 にアップロード\n",
    "\n",
    "import os\n",
    "s3path = os.path.dirname(your_augmented_manifest_file)\n",
    "train_manifest_s3 = s3path + '/train.manifest'\n",
    "valid_manifest_s3 = s3path + '/valid.manifest'\n",
    "! aws s3 cp {train_manifest} {train_manifest_s3}\n",
    "! aws s3 cp {valid_manifest} {valid_manifest_s3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像分類モデルの学習\n",
    "***\n",
    "\n",
    "ここまでで、必要な準備が完了しました。ここでは、画像分類モデルを作ります。始めに ``sagemaker.estimator.Estimator`` オブジェクトを作ります。この estimator から学習ジョブを立ち上げます。こちらも特に変更が必要な部分はありません。\n",
    "\n",
    "## 学習パラメータ\n",
    "\n",
    "モデルを学習するにあたって、2種類のパラメータを設定する必要があります。1つは学習ジョブの設定、もう 1つは画像分類モデルのハイパーパラメータです。\n",
    "\n",
    "学習ジョブの設定には以下のようなものがあります。\n",
    "\n",
    "* **学習インスタンスの数**: 学習ジョブで使用するインスタンスの数です。1 よりも大きな値を設定することで分散学習を実行することができます。ただし、画像分類のビルトインアルゴリズムは Pipe モード時の分散学習に対応していません。本ノートブックのように Amazon SageMaker Ground Truth が出力した拡張マニフェストファイルを使用する場合はファイル転送を Pipe モードにする必要があるため、分散学習を使用することはできませんのでご注意ください。\n",
    "* **学習インスタンスタイプ**: 学習ジョブで使用するインスタンスタイプです。画像分類のビルトインアルゴリズムでは、p2 または p3 の GPU インスタンスのみをサポートします。\n",
    "* **出力パス**: 学習ジョブの出力先となる S3 のパスです、"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ジョブの設定\n",
    "\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.p2.xlarge',\n",
    "                                      volume_size = 50,\n",
    "                                      max_run = 360000,\n",
    "                                      input_mode = 'Pipe',\n",
    "                                      output_path=s3_output_location,\n",
    "                                      sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像分類モデルのハイパーパラメータには以下のようなものがあります。\n",
    "\n",
    "* **num_layers**: モデルネットワークの層の数です。このサンプルでは 18 を使用しますが、[18、34、50、101、152、200] の中から選択できます。\n",
    "* **use_pretrained_model**: 1 を設定することで学習済みモデルを使って転移学習をすることができます。\n",
    "* **image_shape**: 学習に使用する画像のサイズです。チャネル数、高さ、幅、の順で設定します。実際の画像サイズより大きな値を設定しないようにしてください。\n",
    "* **num_classes**: 画像分類の分類ラベルの数です。Imagenet は 1000 クラスの分類ですが、実際に使用したいラベルの数に合わせてクラスの数を変更します。2 匹の猫を分類するモデルを作る場合は、2 を設定します。\n",
    "* **num_training_samples**: 学習に用いる画像の枚数を設定します。\n",
    "* **mini_batch_size**: 各ミニバッチで使用する学習サンプル数です。分散学習では、バッチごとに使用される学習サンプル数は N * mini_batch_size となり、Nは訓練を実行するホストの数を意味します。\n",
    "* **epochs**: 学習エポック数です。\n",
    "* **learning_rate**: 学習率です。\n",
    "* **precision_dtype**: 学習データの精度 (default: float32) です。float16 に設定した場合、学習は mixed_precision モードとなり、float32 よりも高速に学習します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像分類モデルのハイパーパラメータの設定\n",
    "\n",
    "ic.set_hyperparameters(num_layers=18,\n",
    "                             use_pretrained_model=1,\n",
    "                             image_shape = str(channel)+','+str(height)+','+str(width),\n",
    "                             num_classes=len(object_categories),\n",
    "                             num_training_samples=num_training_samples,\n",
    "                             mini_batch_size=4,\n",
    "                             epochs=20,\n",
    "                             learning_rate=0.01,\n",
    "                             precision_dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 入力データの設定\n",
    "\n",
    "学習データの形式を定義します。今回は Amazon SageMaker Ground Truth で作成した拡張マニフェスト形式のファイルを使用するための設定をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拡張マニフェスト形式のファイルを学習データとして使用するよう設定\n",
    "\n",
    "train_data = sagemaker.inputs.TrainingInput(train_manifest_s3,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', labeling_job_name]) \n",
    "validation_data = sagemaker.inputs.TrainingInput(valid_manifest_s3,\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names=['source-ref', labeling_job_name]) \n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の開始\n",
    "\n",
    "定義した estimator の fit() を実行して学習ジョブを開始します。ログの最後には、\n",
    "\n",
    "```\n",
    "Training seconds: 255\n",
    "Billable seconds: 255\n",
    "```\n",
    "のように、学習ジョブに対して課金される対象となる時間が秒単位で表示されます。\n",
    "\n",
    "\n",
    "> **注意： ResourceLimitExceeded というエラーが出たら**<br>\n",
    "作ったばかりの新しい AWSアカウントを使用する場合など、ノートブック実行中に ResourceLimitExceeded というエラーが出ることがあります。その場合は [サポートセンター](https://console.aws.amazon.com/support/home#/) から 「ケースの作成」 をクリックしたのち 「サービス制限の緩和」を選択し、以下の設定でケースを作成します。\n",
    "> - 制限タイプ：SageMaker\n",
    "> - リージョン：米国東部（バージニア北部）　※実際に使用するリージョンを選択してください\n",
    "> - リソースタイプ：学習実行時にエラーが出た場合は「SageMaker のトレーニング」、推論時にエラーが出た場合は「SageMaker のホスト」\n",
    "> - 制限：使用するインスタンスタイプ\n",
    "> - 申請理由の説明：ハンズオンで使用するため、など"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-13 07:29:14 Starting - Starting the training job...\n",
      "2021-10-13 07:29:38 Starting - Launching requested ML instancesProfilerReport-1634110154: InProgress\n",
      "......\n",
      "2021-10-13 07:30:38 Starting - Preparing the instances for training...............\n",
      "2021-10-13 07:33:07 Downloading - Downloading input data...\n",
      "2021-10-13 07:33:43 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/image_classification/default-input.json: {'use_pretrained_model': 0, 'num_layers': 152, 'epochs': 30, 'learning_rate': 0.1, 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': 32, 'image_shape': '3,224,224', 'precision_dtype': 'float32'}\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'num_classes': '5', 'num_training_samples': '993', 'use_pretrained_model': '1', 'precision_dtype': 'float32', 'num_layers': '18', 'epochs': '20', 'image_shape': '3,600,800', 'learning_rate': '0.01', 'mini_batch_size': '4'}\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] Final configuration: {'use_pretrained_model': '1', 'num_layers': '18', 'epochs': '20', 'learning_rate': '0.01', 'lr_scheduler_factor': 0.1, 'optimizer': 'sgd', 'momentum': 0, 'weight_decay': 0.0001, 'beta_1': 0.9, 'beta_2': 0.999, 'eps': 1e-08, 'gamma': 0.9, 'mini_batch_size': '4', 'image_shape': '3,600,800', 'precision_dtype': 'float32', 'num_classes': '5', 'num_training_samples': '993'}\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] use_pretrained_model: 1\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] multi_label: 0\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] Using pretrained model for initializing weights and transfer learning.\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] ---- Parameters ----\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] num_layers: 18\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] data type: <class 'numpy.float32'>\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] epochs: 20\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] optimizer: sgd\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] momentum: 0.9\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] weight_decay: 0.0001\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] learning_rate: 0.01\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] num_training_samples: 993\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] mini_batch_size: 4\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] image_shape: 3,600,800\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] num_classes: 5\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] augmentation_type: None\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] kv_store: device\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:48 INFO 140285547784000] --------------------\u001b[0m\n",
      "\u001b[34m[07:33:48] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.6753.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[34m[07:33:48] /opt/brazil-pkg-cache/packages/AIAlgorithmsMXNet/AIAlgorithmsMXNet-1.3.x_ecl_Cuda_10.1.x.6753.0/AL2_x86_64/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[34m[10/13/2021 07:33:49 INFO 140285547784000] Setting number of threads: 3\u001b[0m\n",
      "\u001b[34m[07:33:53] /opt/brazil-pkg-cache/packages/AIApplicationsPipeIterators/AIApplicationsPipeIterators-1.0.1256.0/AL2_x86_64/generic-flavor/src/data_iter/src/utils.h:36: Got empty matrix when decoding one of the images\u001b[0m\n",
      "\u001b[34m[07:33:53] /opt/brazil-pkg-cache/packages/AIApplicationsPipeIterators/AIApplicationsPipeIterators-1.0.1256.0/AL2_x86_64/generic-flavor/src/data_iter/src/utils.h:81: Customer Error: Invalid image found. Please ensure data is in one of the expected image formats\u001b[0m\n",
      "\n",
      "2021-10-13 07:34:02 Uploading - Uploading generated training model\n",
      "2021-10-13 07:34:02 Failed - Training job failed\n",
      "ProfilerReport-1634110154: Stopping\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job image-classification-2021-10-13-07-29-14-006: Failed. Reason: ClientError: Invalid image found. Please ensure data is in one of the expected image formats\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-819888737956>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3723\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3724\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3725\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   3282\u001b[0m                 ),\n\u001b[1;32m   3283\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3284\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3285\u001b[0m             )\n\u001b[1;32m   3286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job image-classification-2021-10-13-07-29-14-006: Failed. Reason: ClientError: Invalid image found. Please ensure data is in one of the expected image formats\n"
     ]
    }
   ],
   "source": [
    "ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推論 - 猫を見分けてみよう！\n",
    "\n",
    "***\n",
    "\n",
    "## 推論環境の起動\n",
    "モデルを学習しただけでは何も起こりません。作ったモデルを使って、写真に写っているのがどちらの猫なのかを推論してみましょう。estimator の deploy() を実行して推論環境を立ち上げます。ログにはしばらく `-` が表示され、処理が完了したら `!` が表示されます。**こちらの処理が完了するまでは 5分から 10分程度かかります。**\n",
    "\n",
    "ResourceLimitExceeded というエラーが出たら、[学習の開始](#学習の開始) に記載の手順でサービス制限の緩和を行ってください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sagemaker-ap-northeast-1-430477916104/ic-transfer-learning/output/image-classification-2021-10-13-07-29-14-006/output/model.tar.gz.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-57af0d99e495>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m ic_classifier = ic.deploy(initial_instance_count = 1,\n\u001b[1;32m      4\u001b[0m                                           \u001b[0minstance_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ml.m4.xlarge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                           serializer = IdentitySerializer(content_type='application/x-image'))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, use_compiled_model, wait, model_name, kms_key, data_capture_config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m             \u001b[0mdata_capture_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m         )\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_suffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_sagemaker_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         production_variant = sagemaker.production_variant(\n\u001b[1;32m    713\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstance_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_instance_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccelerator_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36m_create_sagemaker_model\u001b[0;34m(self, instance_type, accelerator_type, tags)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mvpc_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvpc_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0menable_network_isolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menable_network_isolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(self, name, role, container_defs, vpc_config, enable_network_isolation, primary_container, tags)\u001b[0m\n\u001b[1;32m   2657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcreate_model_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClientError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the CreateModel operation: Could not find model data at s3://sagemaker-ap-northeast-1-430477916104/ic-transfer-learning/output/image-classification-2021-10-13-07-29-14-006/output/model.tar.gz."
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import IdentitySerializer\n",
    "\n",
    "ic_classifier = ic.deploy(initial_instance_count = 1,\n",
    "                                          instance_type = 'ml.m4.xlarge',\n",
    "                                          serializer = IdentitySerializer(content_type='application/x-image'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論用画像の準備\n",
    "\n",
    "S3 に保存してある画像をダウンロードして、どちらの猫の写真なのか推論してみます。画像は `/tmp` にダウンロードされます。**S3 のパスは、みなさまの環境に合わせて書き換えてください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像を S3 からローカル（ノートブックインスタンス）の /tmp/にダウンロード\n",
    "\n",
    "!aws s3 cp \"s3://cat-image-classification/cats/DSC_0022.jpg\" /tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ダウンロードした画像を確認します。**`file_name` は先ほどダウンロードした画像の名前に書き換えてください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 画像の表示\n",
    "\n",
    "file_name = '/tmp/DSC_0022.jpg'\n",
    "from IPython.display import Image\n",
    "Image(file_name)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 写真に写っている猫を見分ける（推論の実行）\n",
    "\n",
    "立ち上げた推論環境に写真を送って、写真にどちらの猫が写っているのかを見分けます。推論結果としては、各ラベル（猫の名前）と、写真に写っているのがその猫である確率（probability）が出力されます。そこから、最も probability が高いものを最終結果とします。使用する画像を変えて、何度か推論を試してみましょう！\n",
    "\n",
    "**注意:** 結果がいまひとつの場合、学習に使用する画像を増やす、ハイパーパラメータの epoch の数を増やす、その他のハイパーパラメータチューニングを行うなどで精度の向上が見込めます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロードした写真を読み込んで、推論環境に送り推論結果を取得し、最終結果を表示\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "result = json.loads(ic_classifier.predict(payload))\n",
    "# the result will output the probabilities for all classes\n",
    "# find the class with maximum probability and print the class index\n",
    "index = np.argmax(result)\n",
    "\n",
    "print(\"写っているのは \" + object_categories[index] + \"です！ （probability - \" + str(round(result[index]*100, 1)) + '%）')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リソースの削除\n",
    "***\n",
    "不要な課金を防ぐため、使用しないリソースは削除しましょう。なお、削除したデータは戻せないのでご注意ください。本ノートブックを実行することで使用される AWS サービスは以下の通りです。削除方法は [こちらの記事](https://aws.amazon.com/jp/builders-flash/202005/sagemaker-groundtruth-cat/) の「リソースの削除」の章をご参照ください。\n",
    "- Amazon S3 バケット\n",
    "- Amazon SageMaker ノートブックインスタンス\n",
    "- Amazon SageMaker エンドポイント\n",
    "\n",
    "## 推論環境（エンドポイント）の削除\n",
    "\n",
    "推論環境は立ち上げている間課金されるので、ありったけの猫の写真を見分け終わったら、次のコマンドを実行して推論環境を削除しましょう。delete_endpoint() でエンドポイントを削除することができます。\n",
    "\n",
    "Amazon SageMaker のコンソールからエンドポイント一覧の画面にいき、そちらからエンドポイントを削除することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
